{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop, Train, Deploy Scikit-Learn SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [reference]    \n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-python-sdk/scikit_learn_randomforest/Sklearn_on_SageMaker_end2end.ipynb\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=hLzEHsUSHq4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn # sklearn 버전확인 sklearn = scikit-learn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Import Lib]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "Using bucket sagemaker-ap-northeast-2-918934048065\n"
     ]
    }
   ],
   "source": [
    "import datetime                 #날짜 및 시간 관련 모듈\n",
    "import time                     #시간관련 모듈\n",
    "import tarfile                  #파일 압축 및 해제를 위한 모듈\n",
    "\n",
    "import boto3                    #AWS SD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role                #SageMaker 역할(실행역할을 가져오는 메서드)\n",
    "import sagemaker                                        #SageMaker lib\n",
    "from sklearn.model_selection import train_test_split    # train,test set 분리\n",
    "\n",
    "\n",
    "sm_boto3 = boto3.client(\"sagemaker\")                #SageMaker 클라이언트를 생성합니다. \n",
    "\n",
    "sess = sagemaker.Session()                          #SageMaker 세션을 생성합니다. SageMaker와 상호 작용할 때 사용\n",
    "\n",
    "region = sess.boto_session.region_name              #현재 SageMaker 세션의 리전을 가져와서 region 변수에 저장\n",
    "\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "\n",
    "print(\"Using bucket \" + bucket)                     #SageMaker 버킷의 이름을 출력 버킷(aws s3)(파일 저장하는 곳)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "We load a dataset from sklearn, split it and send it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_json('sqli_query_clean.json')\n",
    "# df = pd.read_csv('security_log_clean.csv',encoding='utf-8')\n",
    "# df = pd.read_csv('security_log_clean.csv')\n",
    "df= pd.read_csv('security_log_complete.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 필요없는 열 제거\n",
    "df.drop('Unnamed: 0', axis =1, inplace =True)\n",
    "# axis =1 : 열  axis =0 : 행 즉, 열을 drop 없애버린다는 이야기\n",
    "\n",
    "# inplace =True 하면 데이터프레임에 바로 적용\n",
    "# df = df.drop('Unnamed: 0', axis =1) 이렇게 안해도 되는거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pattern', 'label'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns #열(특징) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3930aab9d3a38dcf</td>\n",
       "      <td>urlregex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2faf2430c9a04a39</td>\n",
       "      <td>urlregex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15953497afbbaf03</td>\n",
       "      <td>urlregex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/d/msdownload/update/others/2023/08/39551369_5...</td>\n",
       "      <td>urlregex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/c/msdownload/update/others/2023/08/39551110_5...</td>\n",
       "      <td>urlregex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pattern     label\n",
       "0                                   3930aab9d3a38dcf  urlregex\n",
       "1                                   2faf2430c9a04a39  urlregex\n",
       "2                                   15953497afbbaf03  urlregex\n",
       "3  /d/msdownload/update/others/2023/08/39551369_5...  urlregex\n",
       "4  /c/msdownload/update/others/2023/08/39551110_5...  urlregex"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # 데이터프레임 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "valid            12112\n",
       "urlregex          2006\n",
       "accesscontrol     1154\n",
       "shellcode          754\n",
       "upload             540\n",
       "sqli               292\n",
       "webattack          253\n",
       "xss                218\n",
       "includei            60\n",
       "download            57\n",
       "logical_sqli        54\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts() # 어떤 라벨들이 있는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train set, test set split 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['pattern'], df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "trainX = pd.DataFrame(X_train)\n",
    "trainX['label'] = y_train\n",
    "\n",
    "testX = pd.DataFrame(X_test)\n",
    "testX['label'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>d=103&amp;p=hysyfm1wqf bf53ag7l7npy0whwo41skgl3nmw...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7540</th>\n",
       "      <td>p1=1691586991&amp;p2=404&amp;p3=2&amp;p4=wzuaexh64bu/rhhm2...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12272</th>\n",
       "      <td>c=13&amp;p=1uhcd0lcweyfy1ijzvajh72l38d_9k4e0bgef_d...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10710</th>\n",
       "      <td>p1=1691589321&amp;p2=404&amp;p3=2&amp;p4=g rfnhkuec7x0zfqq...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>param=&lt;!entity xxe system \"file:///etc/passwd\"&gt;</td>\n",
       "      <td>shellcode</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pattern      label\n",
       "8762   d=103&p=hysyfm1wqf bf53ag7l7npy0whwo41skgl3nmw...      valid\n",
       "7540   p1=1691586991&p2=404&p3=2&p4=wzuaexh64bu/rhhm2...      valid\n",
       "12272  c=13&p=1uhcd0lcweyfy1ijzvajh72l38d_9k4e0bgef_d...      valid\n",
       "10710  p1=1691589321&p2=404&p3=2&p4=g rfnhkuec7x0zfqq...      valid\n",
       "3646     param=<!entity xxe system \"file:///etc/passwd\">  shellcode"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.head() # 데이터가 제대로 나눠져 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainx, testx 데이터 나눠놓은거 to_csv 해서 csv 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "trainX.to_csv(\"attack_train.csv\")\n",
    "\n",
    "testX.to_csv(\"attack_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 만들어진 csv 파일 s3 버킷(파일 저장하는 곳)에다가 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "trainpath = sess.upload_data(\n",
    "    path=\"attack_train.csv\", bucket=bucket, key_prefix=\"sagemaker/sklearncontainer\"\n",
    ")\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path=\"attack_test.csv\", bucket=bucket, key_prefix=\"sagemaker/sklearncontainer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-918934048065/sagemaker/sklearncontainer/attack_train.csv'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainpath           # 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-918934048065/sagemaker/sklearncontainer/attack_test.csv'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpath            # 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Writing a *Script Mode* script\n",
    "The below script contains both training and inference functionality and can run both in SageMaker Training hardware or locally (desktop, SageMaker notebook, on prem, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [reference]  \n",
    "- script.py 작성하는 레퍼런스   \n",
    "https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#preparing-the-scikit-learn-training-script\n",
    "\n",
    "\n",
    "- (sklearn)TFidfVectorizer docs   \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "\n",
    "- (sklearn)Support Vector Machines docs   \n",
    "https://scikit-learn.org/stable/modules/svm.html#svc   \n",
    "\n",
    "\n",
    "- (sklearn) make_pipeline  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ADD EXCEPTION(when len(jsonlist) !=4 -> 예외처리) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile script.py\n",
    "\n",
    "# import argparse         # 명령행 인수를 파싱하기 위한 lib\n",
    "# import joblib           # 모델을 저장하고 불러오기 위한 lib\n",
    "# import os               # os <-경로등을 위한 라이브러리\n",
    "\n",
    "# import numpy as np      # numpy,pandas 데이터 처리 및 조작를 위한  lib\n",
    "# import pandas as pd\n",
    "# import sklearn          # scikit-learn 라이브러리\n",
    "\n",
    "# # from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer     #\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import make_pipeline                      #여러 함수를 하나로 묶는 방법\n",
    "# from sklearn.model_selection import GridSearchCV, train_test_split      \n",
    "\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "# import json         #json 형태로 데이터 전달해주기 위한 라이브러리\n",
    "\n",
    "# # inference functions ---------------\n",
    "\n",
    "\n",
    "# # Load the model\n",
    "# def model_fn(model_dir):\n",
    "#     \"\"\"\n",
    "#     Load the trained model from the specified model directory.\n",
    "\n",
    "#     Parameters:\n",
    "#     model_dir (str): Path to the directory where the model is saved.\n",
    "\n",
    "#     Returns:\n",
    "#     model: Loaded machine learning model.\n",
    "#     \"\"\"\n",
    "#     model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# # Modify input function to accept JSON list with four values\n",
    "# def input_fn(request_body, request_content_type):\n",
    "#     \"\"\"\n",
    "#     Parse the incoming JSON input.\n",
    "\n",
    "#     Parameters:\n",
    "#     request_body (str): Request body containing input data in JSON format (a list with four values).\n",
    "#     request_content_type (str): Content type of the request.\n",
    "\n",
    "#     Returns:\n",
    "#     input_data: Parsed input data (a list of four values).\n",
    "#     \"\"\"\n",
    "#     if request_content_type == \"application/json\":\n",
    "#         try:\n",
    "#             input_data = json.loads(request_body)\n",
    "#             if len(input_data) != 4:\n",
    "#                 raise ValueError(\"Invalid input. Expected a JSON list with four values.\")\n",
    "#             return input_data\n",
    "#         except ValueError as e:\n",
    "#             raise ValueError(\"Invalid input. Unable to parse JSON input: {}\".format(e))\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid content type. Expected application/json.\")\n",
    "\n",
    "# # Modify prediction function to use the model with the extracted values\n",
    "# def predict_fn(input_data, model):\n",
    "#     \"\"\"\n",
    "#     Perform predictions using the loaded model.\n",
    "\n",
    "#     Parameters:\n",
    "#     input_data: Input data for prediction (a list of four values).\n",
    "#     model: Loaded machine learning model.\n",
    "\n",
    "#     Returns:\n",
    "#     predictions: Predicted labels.\n",
    "#     \"\"\"\n",
    "#     if model is None:\n",
    "#         raise RuntimeError(\"Model has not been loaded.\")\n",
    "    \n",
    "#     # Ensure that input_data is a list\n",
    "#     if not isinstance(input_data, list) or len(input_data) != 4:\n",
    "#         raise ValueError(\"Invalid input. Expected a list with four values.\")\n",
    "    \n",
    "#     # Convert the input list to a numpy array and reshape it to match the input format\n",
    "#     input_data = np.array(input_data).reshape(1, -1)\n",
    "    \n",
    "#     predictions = model.predict(input_data)\n",
    "#     return predictions.tolist()\n",
    "\n",
    "# # Modify output function to format the prediction results\n",
    "# def output_fn(predictions, content_type):\n",
    "#     \"\"\"\n",
    "#     Format the prediction results.\n",
    "\n",
    "#     Parameters:\n",
    "#     predictions: Predicted labels.\n",
    "#     content_type (str): Content type for the output.\n",
    "\n",
    "#     Returns:\n",
    "#     output_data: Formatted output data.\n",
    "#     \"\"\"\n",
    "#     if content_type == \"application/json\":\n",
    "#         try:\n",
    "#             output_data = json.dumps(predictions)\n",
    "#             return output_data, content_type\n",
    "#         except ValueError as e:\n",
    "#             raise ValueError(\"Unable to serialize the prediction output to JSON: {}\".format(e))\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid content type. Expected application/json.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"[INFO] Extracting arguments\")\n",
    "\n",
    "#     parser = argparse.ArgumentParser()\n",
    "                       \n",
    "#     # Data, model, and output directories\n",
    "#     parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "#     parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "#     parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "#     parser.add_argument(\"--train-file\", type=str, default=\"attack_train.csv\")\n",
    "#     parser.add_argument(\"--test-file\", type=str, default=\"attack_test.csv\")   \n",
    "\n",
    "\n",
    "#     args, _ = parser.parse_known_args()\n",
    "    \n",
    "#     print(\"SKLearn Version: \", sklearn.__version__)         #version check\n",
    "#     print(\"Joblib Version: \", joblib.__version__)           #version check\n",
    "\n",
    "\n",
    "#     print(\"[INFO] Reading data\")\n",
    "#     print()\n",
    "#     train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "#     test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "#     print(\"building training and testing datasets\")\n",
    "#     X_train = train_df['pattern']\n",
    "#     X_test = test_df['pattern']\n",
    "#     y_train = train_df['label']\n",
    "#     y_test = test_df['label']\n",
    "    \n",
    "#     # train\n",
    "#     print(\"training model\")\n",
    "\n",
    "    \n",
    "#     model = make_pipeline(TfidfVectorizer(input = 'content',\n",
    "#                                           lowercase = True,\n",
    "#                                           analyzer = 'char',\n",
    "#                                           max_features = 1024,\n",
    "#                                           ngram_range = (1,2),\n",
    "#                                           decode_error=\"ignore\"),\n",
    "#                           SVC(C=10, kernel ='rbf'))\n",
    "\n",
    "\n",
    "\n",
    "#     # 모델 저장\n",
    "#     model.fit(X_train, y_train)\n",
    "#     # persist model\n",
    "#     path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "#     joblib.dump(model, path)\n",
    "#     print(\"model persisted at \" + path)\n",
    "#     # print(args.min_samples_leaf)\n",
    "    \n",
    "    \n",
    "#     y_pred_test = model.predict(X_test)\n",
    "#     test_acc = accuracy_score(y_test,y_pred_test)\n",
    "#     test_rep = classification_report(y_test,y_pred_test)\n",
    "\n",
    "#     print()\n",
    "#     print(\"---- METRICS RESULTS FOR TESTING DATA ----\")\n",
    "#     print()\n",
    "#     print(\"Total Rows are: \", X_test.shape[0])\n",
    "#     print('[TESTING] Model Accuracy is: ', test_acc)\n",
    "#     print('[TESTING] Testing Report: ')\n",
    "#     print(test_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import argparse         # 명령행 인수를 파싱하기 위한 lib\n",
    "import joblib           # 모델을 저장하고 불러오기 위한 lib\n",
    "import os               # os <-경로등을 위한 라이브러리\n",
    "\n",
    "import numpy as np      # numpy,pandas 데이터 처리 및 조작를 위한  lib\n",
    "import pandas as pd\n",
    "import sklearn          # scikit-learn 라이브러리\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer     #\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline                      #여러 함수를 하나로 묶는 방법\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split      \n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "import json         #json 형태로 데이터 전달해주기 위한 라이브러리\n",
    "\n",
    "# inference functions ---------------\n",
    "\n",
    "\n",
    "# Load the model\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the trained model from the specified model directory.\n",
    "\n",
    "    Parameters:\n",
    "    model_dir (str): Path to the directory where the model is saved.\n",
    "\n",
    "    Returns:\n",
    "    model: Loaded machine learning model.\n",
    "    \"\"\"\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "# Input function to parse the incoming JSON input\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"\n",
    "    Parse the incoming JSON input.\n",
    "\n",
    "    Parameters:\n",
    "    request_body (str): Request body containing input data in JSON format.\n",
    "    request_content_type (str): Content type of the request.\n",
    "\n",
    "    Returns:\n",
    "    input_data: Parsed input data.\n",
    "    \"\"\"\n",
    "    if request_content_type == \"application/json\":\n",
    "        try:\n",
    "            input_data = json.loads(request_body)\n",
    "            return input_data\n",
    "        except ValueError as e:\n",
    "            raise ValueError(\"Invalid input. Unable to parse JSON input: {}\".format(e))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid content type. Expected application/json.\")\n",
    "\n",
    "        \n",
    "        \n",
    "# Prediction function\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    Perform predictions using the loaded model.\n",
    "\n",
    "    Parameters:\n",
    "    input_data: Input data for prediction.\n",
    "    model: Loaded machine learning model.\n",
    "\n",
    "    Returns:\n",
    "    predictions: Predicted labels.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model has not been loaded.\")\n",
    "\n",
    "    predictions = model.predict(input_data)\n",
    "    return predictions.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# Output function to format the prediction results\n",
    "def output_fn(predictions, content_type):\n",
    "    \"\"\"\n",
    "    Format the prediction results.\n",
    "\n",
    "    Parameters:\n",
    "    predictions: Predicted labels.\n",
    "    content_type (str): Content type for the output.\n",
    "\n",
    "    Returns:\n",
    "    output_data: Formatted output data.\n",
    "    \"\"\"\n",
    "    if content_type == \"application/json\":\n",
    "        try:\n",
    "            output_data = json.dumps(predictions)\n",
    "            return output_data, content_type\n",
    "        except ValueError as e:\n",
    "            raise ValueError(\"Unable to serialize the prediction output to JSON: {}\".format(e))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid content type. Expected application/json.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"[INFO] Extracting arguments\")\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "                       \n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"attack_train.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"attack_test.csv\")   \n",
    "\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print(\"SKLearn Version: \", sklearn.__version__)         #version check\n",
    "    print(\"Joblib Version: \", joblib.__version__)           #version check\n",
    "\n",
    "\n",
    "    print(\"[INFO] Reading data\")\n",
    "    print()\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print(\"building training and testing datasets\")\n",
    "    X_train = train_df['pattern']\n",
    "    X_test = test_df['pattern']\n",
    "    y_train = train_df['label']\n",
    "    y_test = test_df['label']\n",
    "    \n",
    "    # train\n",
    "    print(\"training model\")\n",
    "\n",
    "    \n",
    "    model = make_pipeline(TfidfVectorizer(input = 'content',\n",
    "                                          lowercase = True,\n",
    "                                          analyzer = 'char',\n",
    "                                          max_features = 1024,\n",
    "                                          ngram_range = (1,2),\n",
    "                                          decode_error=\"ignore\"),\n",
    "                          SVC(C=10, kernel ='rbf'))\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 저장\n",
    "    model.fit(X_train, y_train)\n",
    "    # persist model\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print(\"model persisted at \" + path)\n",
    "    # print(args.min_samples_leaf)\n",
    "    \n",
    "    \n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test,y_pred_test)\n",
    "    test_rep = classification_report(y_test,y_pred_test)\n",
    "\n",
    "    print()\n",
    "    print(\"---- METRICS RESULTS FOR TESTING DATA ----\")\n",
    "    print()\n",
    "    print(\"Total Rows are: \", X_test.shape[0])\n",
    "    print('[TESTING] Model Accuracy is: ', test_acc)\n",
    "    print('[TESTING] Testing Report: ')\n",
    "    print(test_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local training\n",
    "Script arguments allows us to remove from the script any SageMaker-specific configuration, and run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracting arguments\n",
      "SKLearn Version:  1.0.1\n",
      "Joblib Version:  1.3.2\n",
      "[INFO] Reading data\n",
      "\n",
      "building training and testing datasets\n",
      "training model\n",
      "model persisted at ./model.joblib\n",
      "\n",
      "---- METRICS RESULTS FOR TESTING DATA ----\n",
      "\n",
      "Total Rows are:  3500\n",
      "[TESTING] Model Accuracy is:  0.9788571428571429\n",
      "[TESTING] Testing Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "accesscontrol       0.99      0.97      0.98       226\n",
      "     download       0.93      1.00      0.96        13\n",
      "     includei       1.00      1.00      1.00        11\n",
      " logical_sqli       0.86      1.00      0.92         6\n",
      "    shellcode       0.94      0.99      0.97       157\n",
      "         sqli       0.96      0.88      0.92        50\n",
      "       upload       0.68      1.00      0.81        99\n",
      "     urlregex       0.98      1.00      0.99       428\n",
      "        valid       1.00      1.00      1.00      2404\n",
      "    webattack       1.00      0.20      0.34        59\n",
      "          xss       0.95      0.85      0.90        47\n",
      "\n",
      "     accuracy                           0.98      3500\n",
      "    macro avg       0.94      0.90      0.89      3500\n",
      " weighted avg       0.98      0.98      0.98      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ! python script.py --C 10 \\\n",
    "#                    --model-dir ./ \\\n",
    "#                    --train ./ \\\n",
    "#                    --test ./ \\\n",
    "\n",
    "\n",
    "! python script.py --model-dir ./ \\\n",
    "                   --train ./ \\\n",
    "                   --test ./ \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching a training job with the Python SDK   \n",
    "\n",
    "[reference]    \n",
    "https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Import necessary module from the SageMaker Python SDK\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# Specify the scikit-learn framework version to use\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "# Create an SKLearn estimator with the specified configuration\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"script.py\",         # The entry point script for training\n",
    "    role=get_execution_role(),       # SageMaker IAM role for executing training jobs\n",
    "    instance_count=1,                # Number of EC2 instances to use for training\n",
    "    instance_type=\"ml.m5.large\",     # Type of EC2 instance for training\n",
    "    framework_version=FRAMEWORK_VERSION,  # The version of scikit-learn framework to use\n",
    "    base_job_name=\"svc-custom-sklearn\"  # Base name for the training job\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: svc-custom-sklearn-2023-11-21-02-23-50-773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-11-21 02:23:51 Starting - Starting the training job...\n",
      "2023-11-21 02:24:07 Starting - Preparing the instances for training......\n",
      "2023-11-21 02:25:05 Downloading - Downloading input data...\n",
      "2023-11-21 02:25:40 Training - Downloading the training image...\n",
      "2023-11-21 02:26:10 Training - Training image download completed. Training in progress.\u001b[34m2023-11-21 02:26:13,212 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2023-11-21 02:26:13,215 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-21 02:26:13,257 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-11-21 02:26:13,419 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-21 02:26:13,431 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-21 02:26:13,443 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-21 02:26:13,453 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"svc-custom-sklearn-2023-11-21-02-23-50-773\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-918934048065/svc-custom-sklearn-2023-11-21-02-23-50-773/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-918934048065/svc-custom-sklearn-2023-11-21-02-23-50-773/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"svc-custom-sklearn-2023-11-21-02-23-50-773\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-918934048065/svc-custom-sklearn-2023-11-21-02-23-50-773/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python script.py\u001b[0m\n",
      "\u001b[34m[INFO] Extracting arguments\u001b[0m\n",
      "\u001b[34mSKLearn Version:  0.23.2\u001b[0m\n",
      "\u001b[34mJoblib Version:  1.2.0\u001b[0m\n",
      "\u001b[34m[INFO] Reading data\u001b[0m\n",
      "\u001b[34mbuilding training and testing datasets\u001b[0m\n",
      "\u001b[34mtraining model\u001b[0m\n",
      "\u001b[34mmodel persisted at /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34m---- METRICS RESULTS FOR TESTING DATA ----\u001b[0m\n",
      "\u001b[34mTotal Rows are:  3500\u001b[0m\n",
      "\u001b[34m[TESTING] Model Accuracy is:  0.9788571428571429\u001b[0m\n",
      "\u001b[34m[TESTING] Testing Report: \n",
      "               precision    recall  f1-score   support\u001b[0m\n",
      "\u001b[34maccesscontrol       0.99      0.97      0.98       226\n",
      "     download       0.93      1.00      0.96        13\n",
      "     includei       1.00      1.00      1.00        11\n",
      " logical_sqli       0.86      1.00      0.92         6\n",
      "    shellcode       0.94      0.99      0.97       157\n",
      "         sqli       0.96      0.88      0.92        50\n",
      "       upload       0.68      1.00      0.81        99\n",
      "     urlregex       0.98      1.00      0.99       428\n",
      "        valid       1.00      1.00      1.00      2404\n",
      "    webattack       1.00      0.20      0.34        59\n",
      "          xss       0.95      0.85      0.90        47\n",
      "     accuracy                           0.98      3500\n",
      "    macro avg       0.94      0.90      0.89      3500\n",
      " weighted avg       0.98      0.98      0.98      3500\u001b[0m\n",
      "\u001b[34m2023-11-21 02:26:27,551 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-11-21 02:26:41 Uploading - Uploading generated training model\n",
      "2023-11-21 02:26:41 Completed - Training job completed\n",
      "Training seconds: 97\n",
      "Billable seconds: 97\n"
     ]
    }
   ],
   "source": [
    "# launch training job, with asynchronous call\n",
    "sklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Model Artifacts(model.tar.gz) into the S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-11-21 02:26:41 Starting - Preparing the instances for training\n",
      "2023-11-21 02:26:41 Downloading - Downloading input data\n",
      "2023-11-21 02:26:41 Training - Training image download completed. Training in progress.\n",
      "2023-11-21 02:26:41 Uploading - Uploading generated training model\n",
      "2023-11-21 02:26:41 Completed - Training job completed\n",
      "Model artifact persisted at s3://sagemaker-ap-northeast-2-918934048065/svc-custom-sklearn-2023-11-21-02-23-50-773/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Wait for the completion of the latest training job and retrieve logs\n",
    "sklearn_estimator.latest_training_job.wait(logs=\"None\")\n",
    "\n",
    "# Retrieve the S3 path of the model artifact from the completed training job\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "# Print the S3 path where the model artifact is stored\n",
    "print(\"Model artifact persisted at \" + artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Sagemaker Endpoint(API) for trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# Define a unique model name based on the current timestamp\n",
    "# model_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_name = \"pyree\"\n",
    "\n",
    "# Create a SageMaker SKLearnModel\n",
    "model = SKLearnModel(\n",
    "    name=model_name,             # Name for the SageMaker model\n",
    "    model_data=artifact,         # S3 path of the model artifact obtained earlier\n",
    "    role=get_execution_role(),   # IAM role for accessing resources\n",
    "    entry_point=\"script.py\",     # Entry point script for inference\n",
    "    framework_version=FRAMEWORK_VERSION  # Scikit-learn framework version\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointName=Custom-sklearn-model-2023-11-21-02-27-08\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: pyree\n",
      "WARNING:sagemaker:Using already existing model: pyree\n",
      "INFO:sagemaker:Creating endpoint-config with name Custom-sklearn-model-2023-11-21-02-27-08\n",
      "INFO:sagemaker:Creating endpoint with name Custom-sklearn-model-2023-11-21-02-27-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint Custom-sklearn-model-2023-11-21-02-27-08: Failed. Reason: Failed to download model data from URL \"s3://sagemaker-ap-northeast-2-918934048065/svc-custom-sklearn-2023-10-21-15-42-21-683/output/model.tar.gz\". Please ensure that there is an object located at the URL and that the role passed to CreateModel has permissions to download the object..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEndpointName=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(endpoint_name))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Deploy the model to a SageMaker endpoint\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Number of initial instances for the endpoint\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mml.c5.xlarge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Type of EC2 instance for the endpoint\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Name of the endpoint to be created\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Optional: endpoint configuration (you can uncomment and use if needed)\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# endpoint_config=my_endpoint_config,\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/model.py:1459\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_explainer_enabled:\n\u001b[1;32m   1457\u001b[0m     explainer_config_dict \u001b[38;5;241m=\u001b[39m explainer_config\u001b[38;5;241m.\u001b[39m_to_request_dict()\n\u001b[0;32m-> 1459\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_from_production_variants\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduction_variants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mproduction_variant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls:\n\u001b[1;32m   1471\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:4851\u001b[0m, in \u001b[0;36mSession.endpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict)\u001b[0m\n\u001b[1;32m   4848\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating endpoint-config with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m   4849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_endpoint_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_options)\n\u001b[0;32m-> 4851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\n\u001b[1;32m   4853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:4196\u001b[0m, in \u001b[0;36mSession.create_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   4192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_endpoint(\n\u001b[1;32m   4193\u001b[0m     EndpointName\u001b[38;5;241m=\u001b[39mendpoint_name, EndpointConfigName\u001b[38;5;241m=\u001b[39mconfig_name, Tags\u001b[38;5;241m=\u001b[39mtags\n\u001b[1;32m   4194\u001b[0m )\n\u001b[1;32m   4195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 4196\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m endpoint_name\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:4548\u001b[0m, in \u001b[0;36mSession.wait_for_endpoint\u001b[0;34m(self, endpoint, poll)\u001b[0m\n\u001b[1;32m   4542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   4543\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   4544\u001b[0m             message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   4545\u001b[0m             allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   4546\u001b[0m             actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   4547\u001b[0m         )\n\u001b[0;32m-> 4548\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   4549\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   4550\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   4551\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   4552\u001b[0m     )\n\u001b[1;32m   4553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint Custom-sklearn-model-2023-11-21-02-27-08: Failed. Reason: Failed to download model data from URL \"s3://sagemaker-ap-northeast-2-918934048065/svc-custom-sklearn-2023-10-21-15-42-21-683/output/model.tar.gz\". Please ensure that there is an object located at the URL and that the role passed to CreateModel has permissions to download the object.."
     ]
    }
   ],
   "source": [
    "# Define a unique endpoint name based on the current timestamp\n",
    "\n",
    "endpoint_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "# endpoint_name = \"pyree\"\n",
    "\n",
    "# Print the endpoint name\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "# Deploy the model to a SageMaker endpoint\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,     # Number of initial instances for the endpoint\n",
    "    instance_type=\"ml.c5.xlarge\", # Type of EC2 instance for the endpoint\n",
    "    endpoint_name=endpoint_name,  # Name of the endpoint to be created\n",
    "    \n",
    "    # Optional: endpoint configuration (you can uncomment and use if needed)\n",
    "    # endpoint_config=my_endpoint_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative : invoke with boto3\n",
    "\n",
    "[reference]  \n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints-invoke.html   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-Type : application/json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "endpoint_name = predictor.endpoint\n",
    "print(endpoint_name)\n",
    "\n",
    "# Print the prediction result\n",
    "input_data = [\"param=mv a b\", \"1=1,kwqdjqwkd\", \"2faf2430c9a04a39\", \"/erpuupdate2/erpuupdateservice.asmx\"]\n",
    "# Convert the input data to JSON format\n",
    "input_json = json.dumps(input_data)\n",
    "\n",
    "# Send a request to the endpoint for prediction\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=input_json,\n",
    ")\n",
    "\n",
    "# Parse the response\n",
    "result = json.loads(response[\"Body\"].read().decode())\n",
    "\n",
    "# Print the prediction result\n",
    "print(\"Prediction result:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't forget to delete the endpoint!\n",
    "\n",
    "\n",
    "- Amazon SageMaker 요금   \n",
    "https://aws.amazon.com/ko/sagemaker/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sm_boto3.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
